{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5LCL0JWCbdWG7PICoFj08",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanarazaaa/Personal-Projects-On-going-/blob/main/face_detection_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Wg1QEGl5Rpx"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "\n",
        "def capture_image():\n",
        "    js = Javascript('''\n",
        "        async function captureImage() {\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'none';\n",
        "            document.body.appendChild(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "            stream.getTracks().forEach(track => track.stop());\n",
        "            video.remove();\n",
        "\n",
        "            const data = canvas.toDataURL('image/jpeg');\n",
        "            google.colab.kernel.invokeFunction('notebook.run_callback', [data], {});\n",
        "        }\n",
        "        captureImage();\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "# This function will be called with the captured image data\n",
        "def save_image(data):\n",
        "    import IPython.display as display\n",
        "    import base64\n",
        "    from PIL import Image\n",
        "    from io import BytesIO\n",
        "\n",
        "    # Decode base64 image data\n",
        "    image_data = base64.b64decode(data.split(',')[1])\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "    image.save('/content/captured_image.jpg')\n",
        "    display.display(image)\n",
        "\n",
        "# Register the callback\n",
        "from google.colab import output\n",
        "output.register_callback('notebook.run_callback', save_image)\n",
        "\n",
        "# Capture image\n",
        "capture_image()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# working\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "# Read the captured image\n",
        "image = cv2.imread('/content/captured_image.jpg')\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Load the Haar Cascade for face detection\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Multi-scale detection using Haar Cascade\n",
        "faces = []\n",
        "scales = [1.05, 1.1, 1.2]  # Multiple scale factors for better detection\n",
        "for scale in scales:\n",
        "    detected_faces = face_cascade.detectMultiScale(\n",
        "        gray,\n",
        "        scaleFactor=scale,\n",
        "        minNeighbors=3,  # Lowered for more faces, can increase for fewer false positives\n",
        "        minSize=(30, 30)\n",
        "    )\n",
        "    faces.extend(detected_faces)\n",
        "\n",
        "# Filter out duplicate faces using Intersection over Union (IoU)\n",
        "def iou(box1, box2):\n",
        "    x1, y1, w1, h1 = box1\n",
        "    x2, y2, w2, h2 = box2\n",
        "\n",
        "    # Calculate the area of intersection\n",
        "    inter_x1 = max(x1, x2)\n",
        "    inter_y1 = max(y1, y2)\n",
        "    inter_x2 = min(x1 + w1, x2 + w2)\n",
        "    inter_y2 = min(y1 + h1, y2 + h2)\n",
        "\n",
        "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
        "    area1 = w1 * h1\n",
        "    area2 = w2 * h2\n",
        "    union_area = area1 + area2 - inter_area\n",
        "\n",
        "    return inter_area / union_area if union_area > 0 else 0\n",
        "\n",
        "# Remove duplicates based on IoU threshold\n",
        "threshold = 0.3  # You can adjust this threshold to your liking\n",
        "unique_faces = []\n",
        "\n",
        "for face in faces:\n",
        "    if not any(iou(face, existing_face) > threshold for existing_face in unique_faces):\n",
        "        unique_faces.append(face)\n",
        "\n",
        "# Draw rectangles around detected faces using Haar Cascade\n",
        "for (x, y, w, h) in unique_faces:\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "# Show the output with face detections\n",
        "cv2_imshow(image)\n",
        "print(f\"Detected {len(unique_faces)} face(s).\")\n"
      ],
      "metadata": {
        "id": "SJfNeDk473NW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}